{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SET UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T00:18:37.071540Z",
     "start_time": "2020-10-23T00:18:37.068545Z"
    }
   },
   "outputs": [],
   "source": [
    "data_directory = '../DATA\\\\DSC2\\\\'\n",
    "david_directory = 'S:\\\\david\\\\fromAymone\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T00:11:30.539652Z",
     "start_time": "2020-10-23T00:11:30.537652Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `save_this_csv_or_xl`()\n",
    "Function to save files with current timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T00:21:51.620726Z",
     "start_time": "2020-10-23T00:21:51.613728Z"
    }
   },
   "outputs": [],
   "source": [
    "# To save files with today's date\n",
    "def save_this_csv_or_xl(df, desired_filename, my_directory = data_directory, filetype = 'csv', timestamp = 'today',\n",
    "                  indx = False):\n",
    "    print(colored('''File will save with the default time stamp `today`. \n",
    "    To Change this chose timestamp = 'today.time.seconds', 'today.time', or 'time' ''', 'magenta'))\n",
    "    \n",
    "    print(colored('''\\nFile will save as .csv by default. \n",
    "    To Change that, chose `filetype = 'xlsx' ''', 'magenta'))\n",
    "    \n",
    "    print(colored('''\\n `index = False` by default. You can choose `index = 'True' ''', 'white'))\n",
    "    \n",
    "    today = str(datetime.today().strftime('%Y-%m-%d'))\n",
    "    time = str(datetime.now().time())[:5]\n",
    "    time_second = str(datetime.now().time())[:8]\n",
    "    today_time = (today+'_'+time.replace(':','.'))\n",
    "    now = (today+'_'+time_second).replace(':','.')\n",
    "    \n",
    "    if timestamp == 'today.time.seconds':\n",
    "        filename_tp = desired_filename+'_'+now\n",
    "        \n",
    "    else:\n",
    "        if timestamp == 'today.time':\n",
    "            filename_tp = desired_filename+'_'+today_time\n",
    "            \n",
    "        else:\n",
    "            if timestamp == 'today':\n",
    "                 filename_tp = desired_filename+'_'+today\n",
    "                    \n",
    "    if filetype == 'csv':\n",
    "        df.to_csv(my_directory+filename_tp+'.csv', index = indx)\n",
    "        \n",
    "    else:\n",
    "        if filetype == 'xlsx':\n",
    "            df.to_excel(my_directory+filename_tp+'.xlsx', index = indx)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prelim Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `transform_manifest()` \n",
    "Function to transform manifest files received from biobank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T21:10:33.895174Z",
     "start_time": "2020-10-08T21:10:33.887175Z"
    }
   },
   "outputs": [],
   "source": [
    "def transform_manifest(df, currend_bid_fieldname, master_list_df = None, \n",
    "                       negative_controls_master_df = None, which_df = None):\n",
    "    # FUNCTION TO \n",
    "    \n",
    "    dsample = df[df[currend_bid_fieldname].str.startswith('A')]\n",
    "   #dsample['Positive Control'] = 'No'\n",
    "    dsample['biobank_id'] = [i.split('A')[1] for i in dsample[currend_bid_fieldname]]\n",
    "    dsample['biobank_id'] = dsample['biobank_id'].astype('int64')\n",
    "    dsample = dsample.drop(currend_bid_fieldname, axis = 1)\n",
    "    #display(dsample.head(5))\n",
    "\n",
    "    if which_df == None:\n",
    "        print(colored(\"which_df default value is None.\\nPlease set it to these possible values: 'positive controls', 'negative controls'  or 'test samples' \", 'red'))    \n",
    "\n",
    "    else:\n",
    "        if which_df == 'positive controls':\n",
    "            ## POSITIVE CONTROLS\n",
    "            d_pos = df[~df[currend_bid_fieldname].str.startswith('A')]\n",
    "            d_pos['Positive Control ID'] = d_pos[currend_bid_fieldname]\n",
    "            DF = d_pos.drop(currend_bid_fieldname, axis = 1)\n",
    "            DF['Positive Control'] = 'Yes'\n",
    "            DF['Negative Control'] = 'No'\n",
    "            print('positive controls nunique(): '+str(DF['Positive Control ID'].nunique()))\n",
    "            #display(DF.head(5))\n",
    "            \n",
    "        else:\n",
    "            if which_df == 'negative controls':\n",
    "                negative_controls = negative_controls_master_df\n",
    "\n",
    "                # NEGATIVE CONTROLS\n",
    "                DF = pd.merge(dsample, negative_controls)\n",
    "                print('negative controls nunique(): '+str(DF.biobank_id.nunique()))\n",
    "                #display(DF.head(5))\n",
    "\n",
    "            else:\n",
    "                if which_df == 'test samples':\n",
    "                    noncontrols_df = master_list_df\n",
    "                    #TEST SAMPLES\n",
    "                    DF = pd.merge(dsample,noncontrols_df)\n",
    "                    print('test samples nunique(): '+str(DF.biobank_id.nunique()))\n",
    "                    #display(DF.head(5))\n",
    "                    \n",
    "                else:\n",
    "                    print(\"Error: please check your spelling for 'which_df'\")\n",
    "                    \n",
    "\n",
    "    return DF\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pull_demographics()` \n",
    "Function to concatenae neg conrols, postive controls and test samples in one file with their respective demogaphics\n",
    "**Uses transform_manifest() and save_this_csv()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_demographics(df, currend_bid_fieldname, save_as_filename):\n",
    "    \n",
    "    which_df = ['test samples','negative controls','positive controls']\n",
    "    \n",
    "    # TEST SAMPLE DEMOGRAPHICS\n",
    "    print(colored(which_df[0], 'magenta'))\n",
    "    DF_sample = transform_manifest(df, currend_bid_fieldname, which_df = which_df[0])\n",
    "    \n",
    "    # NEGATIVE CONTROL DEMOGRAPHICS\n",
    "    print(colored(which_df[1], 'magenta'))\n",
    "    DF_neg = transform_manifest(df, currend_bid_fieldname, which_df= which_df[1])\n",
    "    \n",
    "    # POSITIVE CONTROLS\n",
    "    print(colored(which_df[2], 'magenta'))\n",
    "    DF_pos = transform_manifest(df, currend_bid_fieldname, which_df[2])\n",
    "    display(DF_pos.head(3))\n",
    "    \n",
    "    # PUTTING AL TOGETHER\n",
    "    DF_demograhics = pd.concat([DF_sample, DF_neg], sort = False)\n",
    "    DF_demograhics_all = pd.concat([DF_demograhics, DF_pos], sort = False)\n",
    "    DF_demograhics_all['Negative Control'] = DF_demograhics_all['Negative Control'].fillna('No')\n",
    "    DF_demograhics_all['Positive Control'] = DF_demograhics_all['Positive Control'].fillna('No')\n",
    "    \n",
    "    save_this_csv(DF_demograhics_all, save_as_filename, data_directoty)\n",
    "    save_this_csv(DF_demograhics_all, save_as_filename, david_directory)\n",
    "    \n",
    "    print(colored('Done and Saved!', 'magenta'))\n",
    "    display(DF_demograhics_all.head())\n",
    "\n",
    "    \n",
    "    return DF_demograhics_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to perform each step of the plating strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*'Serum specimens will be sorted in descending order of collection dates. Following this order, the first batch of specimens will consist of approximately 5,000 specimens optimized to 68 well plating.*\n",
    "\n",
    "*The number of specimens sent for testing in subsequent batches will depend on when the last positive specimen is found. The batches will consist of all specimens collected in the week prior to the last positive specimen until there are no positives.*\n",
    "\n",
    "*The samples will be randomized within the state in which they were collected to reduce geographic bias in each batch.  Plate location will also be optimized for biobank pull and not randomized by freezer location.'*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pull_batch()`: function to pull batch of desired size from master sample list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*'Serum specimens will be sorted in descending order of collection dates. Following this order, the first batch of specimens will consist of approximately 5,000 specimens ...'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T19:01:03.204301Z",
     "start_time": "2020-08-05T19:01:03.197301Z"
    }
   },
   "outputs": [],
   "source": [
    "def pull_batch(master_ls, batch_size, batch_number, previous_batch = None):  \n",
    "    '''Sorts sample master file from most recent to oldest and pulls batch of first n (n = desired batch size).\n",
    "       When applicable, excludes list of biobank_ids in the previous batch from new batch\n",
    "       '''\n",
    "    \n",
    "    DF = master_ls[['participant_id','biobank_id','DateBloodSampleCollected', 'DateBloodSampleReceived', 'state', 'Negative Control', 'Positive Control']].drop_duplicates()\n",
    "    \n",
    "    # If there is a previous batch,\n",
    "    # keep only pids that are in the master list and not in the previous batch\n",
    "    # Else, proceed\n",
    "    if previous_batch.empty:\n",
    "        DF = DF\n",
    "        \n",
    "    else:\n",
    "        keep = pd.DataFrame(set(master_ls.biobank_id) - set(previous_batch.biobank_id)).rename(columns = {0:'biobank_id'}) \n",
    "        DF = pd.merge(DF, keep, how = 'inner')\n",
    "    \n",
    "    # Sort Date of collection from most recent to oldest in the master file\n",
    "    # then select the first n(batch size) rows\n",
    "    new_batch = DF.sort_values('DateBloodSampleCollected', ascending= False).iloc[:batch_size,:]\n",
    "    \n",
    "    #new_batch = DF1.sample(n = batch_size, random_state= rand_state)\n",
    "    #new_batch = pd.merge(new_batch, master_list, on = ['participant_id','biobank_id','DateBloodSampleCollected', 'DateBloodSampleReceived'],\n",
    "                         #how = 'left')\n",
    "    print(colored('Batch #' +str(batch_number)+' of ' +str(new_batch.biobank_id.nunique()) + ' participants pulled from Master List, sorted in descending order of collection dates, is ready.', 'blue'))\n",
    "    return new_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `randomize_and_locate()`: Function to randomize entire batch by State and add location columns to batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*'The samples will be randomized based within the state in which they were collected to reduce geographic bias in each batch.'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T13:56:45.439618Z",
     "start_time": "2020-08-05T13:56:45.435617Z"
    }
   },
   "outputs": [],
   "source": [
    "def randomize_and_locate(batch_df, batch_size, rand_state):\n",
    "    '''Function to add bay,freezer and rack location columns to pulled batch and randomize by state entire batch \n",
    "        to get it ready for optimization'''\n",
    "    \n",
    "    # randomize by state = rnadomly shuffle states\n",
    "    batch_n_state = batch_df[['state']].sample(n = batch_size, random_state = rand_state)\n",
    "    batch_n_randomState = batch_df.sample(n = batch_size, random_state= rand_state) \n",
    "    \n",
    "#     # Add back participant_ids to the randomized states\n",
    "#     batch_n_randomState = pd.merge(batch_n, batch_n_state)\n",
    "\n",
    "#     # Add Location/Sequencing Columns to the batch\n",
    "#     batch_n_location = pd.merge(serum_samples_check, \n",
    "#                            batch_n_randomState[['biobank_id','participant_id']].drop_duplicates(), 'right')\n",
    "    \n",
    "    print('Shape check:' + str(batch_n_randomState.shape))\n",
    " \n",
    "    return batch_n_randomState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T21:27:22.224118Z",
     "start_time": "2020-08-31T21:27:22.219117Z"
    }
   },
   "outputs": [],
   "source": [
    "def randomize_state(batch_df, batch_size, rand_state):\n",
    "    '''Function to add bay,freezer and rack location columns to pulled batch and randomize by state entire batch \n",
    "        to get it ready for optimization'''\n",
    "    \n",
    "    # randomize by state = rnadomly shuffle states\n",
    "    batch_n_state = batch_df[['state']].sample(n = batch_size, random_state = rand_state)\n",
    "    batch_n_randomState = batch_df.sample(n = batch_size, random_state= rand_state) \n",
    "    \n",
    "    print('Shape check:' + str(batch_n_randomState.shape))\n",
    " \n",
    "    return batch_n_randomState"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `plate_em()`: Function to Group participants by plates of n size\n",
    "\n",
    "*'Plate location will also be optimized for biobank pull and not randomized by freezer location.'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T19:20:25.570726Z",
     "start_time": "2020-07-24T19:20:25.564732Z"
    }
   },
   "outputs": [],
   "source": [
    "## WHEN WE HAD LOCATION INFORMATION FOR THE BATCHES\n",
    "\n",
    "# def optimize_sequence(n_wells, df):  #df = = samples_groups\n",
    "#     '''Function to Create Optimized Sequence \n",
    "#        Groups participants in plates of n_wells participants\n",
    "#        n_wells is the number of wells/the number of people per plate '''\n",
    "\n",
    "#     # create empty 'plate' column\n",
    "#     df['plate'] = int()\n",
    "    \n",
    "#     # SEQUENCE OPTIMIZATION:\n",
    "#      ## Order the batch by Description (Bay, Freezer), Sequence and Rack (optimum sequence order provided by biobank)\n",
    "#      ## Then assign plate numbers to each participant, starting with plate #1\n",
    "#      ## with n_wells participants per plate \n",
    "#     n = 0\n",
    "#     plate_number = 0\n",
    "\n",
    "#     for pid in df.sort_values(['Description', 'Sequence','Rack']).biobank_id: \n",
    "#         pids_per_well = df.sort_values(['Description', 'Sequence', 'Rack'])[['biobank_id']][n:n_wells+n]\n",
    "#         ind = pids_per_well.index.values\n",
    "#         plate_number += 1\n",
    "\n",
    "#         for i in ind:\n",
    "#             df.loc[i, 'plate'] = plate_number\n",
    "\n",
    "#         n += n_wells\n",
    "        \n",
    "#     display(df[['participant_id','plate']].rename(columns = {'participant_id':'pids_per_plate'}).groupby('plate').count())\n",
    "#     print(colored('Done! We have ' +str(n_wells)+' wells per plate, with ' +str(df.plate.nunique()) + ' plates in total. The last few plates may have different numbers', 'blue'))\n",
    "    \n",
    "#     return  df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T18:50:51.446980Z",
     "start_time": "2020-10-08T18:50:51.439979Z"
    }
   },
   "outputs": [],
   "source": [
    "def plate_em(n_wells, df, rand_state, batch_size):  #df = = samples_groups\n",
    "    '''Function to Create Optimized Sequence \n",
    "       Groups participants in plates of n_wells participants\n",
    "       n_wells is the number of wells/the number of people per plate '''\n",
    "\n",
    "    # create empty 'plate' column\n",
    "    df['plate'] = int()\n",
    "    \n",
    "    # SEQUENCE OPTIMIZATION:\n",
    "     ## Randomly shuffles Pids\n",
    "     ## Then assign plate numbers to each participant, starting with plate #1\n",
    "     ## with n_wells participants per plate \n",
    "    \n",
    "    df = df.sample(n = batch_size, random_state = rand_state)\n",
    "    \n",
    "    n = 0\n",
    "    plate_number = 0\n",
    "    for pid in df.biobank_id: \n",
    "        pids_per_well = df[['biobank_id']][n:n_wells+n]\n",
    "        ind = pids_per_well.index.values\n",
    "        plate_number += 1\n",
    "\n",
    "        for i in ind:\n",
    "            df.loc[i, 'plate'] = plate_number\n",
    "\n",
    "        n += n_wells\n",
    "    \n",
    "    df = df.drop('DateBloodSampleReceived', axis = 1)\n",
    "    display(df[['participant_id','plate']].rename(columns = {'participant_id':'pids_per_plate'}).groupby('plate').count())\n",
    "    print(colored('Done! We have ' +str(n_wells)+' wells per plate, with ' +str(df.plate.nunique()) + ' plates in total. The last few plates may have different numbers', 'blue'))\n",
    "    \n",
    "    return  df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `batch_negative_controls()`: Function to add negative controls, including repeated pids \n",
    "*'2019 matched to date range of the batch with geographic location matching as well'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T14:54:10.820956Z",
     "start_time": "2020-10-09T14:54:10.802891Z"
    }
   },
   "outputs": [],
   "source": [
    "def batch_negative_controls(plated_samples_df, batch_df, negControls_master, unrepeated_negControls, \n",
    "                          number_plates, rand_state, previous_batch_negControls = None, duplicate = 'Yes'):\n",
    "    ''' This funtions select batch negative controls, then appends a repeated list of pids \n",
    "        Then merges with the samples from 2020. This will be the input for the optimization function'''\n",
    "    \n",
    "    # 1 Remove previous batches negative controls from master list, if applicable\n",
    "    if previous_batch_negControls.empty:\n",
    "        negControls_master = negControls_master\n",
    "        \n",
    "    else:\n",
    "        keep = pd.DataFrame(set(negControls_master.biobank_id) - set(previous_batch_negControls.biobank_id)).rename(columns = {0:'biobank_id'}) \n",
    "        negControls_master = pd.merge(negControls_master, keep)\n",
    "        \n",
    "    print(colored('How many negative controls are left in the master list \\nafter removing the negative controls from previous batches? : '+str(negControls_master.biobank_id.nunique()), 'red'))\n",
    "\n",
    "    \n",
    "    # 2 MATCH  negative controls on state\n",
    "    neg_controls_df= pd.merge(negControls_master[['biobank_id', 'participant_id','state', 'DateBloodSampleCollected', 'Negative Control', 'Positive Control']].drop_duplicates(), \n",
    "                                batch_df[['state']].drop_duplicates()).drop_duplicates()#.reset_index()\n",
    "    \n",
    "    \n",
    "    ## needed to make sure I get at least one of each state in neg_contol_df\n",
    "    \n",
    "    #not needed for batch 5\n",
    "#     master_neg_state_matched = pd.DataFrame(columns = ['participant_id','biobank_id','state'])\n",
    "#     for s in neg_controls_df.state.unique():\n",
    "#         df = neg_controls_df[neg_controls_df.state == s][['biobank_id','participant_id','state']].drop_duplicates()\n",
    "#         #display(df.shape)\n",
    "#         df = df.sample(1)\n",
    "#         master_neg_state_matched = pd.concat([master_neg_state_matched, df]).drop_duplicates()\n",
    "    \n",
    "    neg_controls_df = neg_controls_df#master_neg_state_matched\n",
    "    print(colored('\\nHow many negative controls are left in the master list \\nafter removing the negative controls from previous batches and matching on state? : '+str(neg_controls_df.biobank_id.nunique()), 'red'))\n",
    "    print('Any state in the matched df that is not in the batch?:')\n",
    "    display(set(neg_controls_df.state) - set(batch_df.state))\n",
    "    \n",
    "    print(colored('\\nQC State Matching alogirthm: ', 'green'))\n",
    "    print('\\nN Unique states in neg control master list state-matched vs batch_df states: '+str(neg_controls_df.state.nunique()) +', '+ str(batch_df.state.nunique()))\n",
    "    print('Unique states in neg control master list state-matched vs batch_df states: ')\n",
    "    display(neg_controls_df[['state']].drop_duplicates().sort_values('state'), batch_df[['state']].drop_duplicates().sort_values('state'))\n",
    "\n",
    "    ## 3 randomly select the batch negative controls\n",
    "    if duplicate == 'Yes':\n",
    "        n_total_controls = math.floor(number_plates/2)\n",
    "    else:\n",
    "        if duplicate == 'No':\n",
    "            n_total_controls = number_plates\n",
    "\n",
    "    batch_neg_controls_df = neg_controls_df.sample(n = int(n_total_controls), \n",
    "                                                random_state = rand_state).reset_index().drop('index', axis = 1)\n",
    " \n",
    "    batch_neg_controls_df = batch_neg_controls_df.merge(negControls_master[['biobank_id', 'participant_id','state', 'DateBloodSampleCollected', 'Negative Control', 'Positive Control']].drop_duplicates()).drop_duplicates()\n",
    "\n",
    "    batch_neg_controls_df = batch_neg_controls_df.sort_values('biobank_id', ascending = True)\n",
    "    batch_neg_controls_df2 = batch_neg_controls_df.sort_values('biobank_id', ascending = False) # for duplication\n",
    "    batch_neg_controls_df = pd.concat([batch_neg_controls_df,batch_neg_controls_df2])\n",
    "    \n",
    "    \n",
    "\n",
    "    ### 4 Assign negative controls to plates, 1 per plate\n",
    "    batch_neg_controls_df['plate']= int()\n",
    "    batch_neg_controls_df['plate']= range(1,int(number_plates)+1)\n",
    "            \n",
    "#     #repeat\n",
    "#     batch_neg_controls_df2['plate']= int()\n",
    "#     batch_neg_controls_df2['plate']= range(int(number_plates/2), (int(number_plates)))\n",
    "    \n",
    "    print(colored('QC State Matching alogirthm 2: ', 'green'))\n",
    "    \n",
    "    print('\\nN Unique states in batch neg controls vs batch_df states: '+str(batch_neg_controls_df.state.nunique()) +', '+ str(batch_df.state.nunique()))\n",
    "    print('Unique states in batch neg controls vs batch_df states: ')\n",
    "    display(batch_neg_controls_df[['state']].drop_duplicates().sort_values('state'), batch_df[['state']].drop_duplicates().sort_values('state'))\n",
    "\n",
    "    print(colored('Other QCs: ', 'green'))\n",
    "    print('unique pids:' + str(batch_neg_controls_df.biobank_id.nunique()))\n",
    "    print('count of pids:' + str(batch_neg_controls_df.biobank_id.count()))\n",
    "    print('number of plates (unique and count):' + str(batch_neg_controls_df.plate.nunique())+' and ' + str(batch_neg_controls_df.plate.count()))\n",
    "    print('shape:' + str(batch_neg_controls_df.shape))\n",
    "    \n",
    "    #batch_neg_controls_df = batch_neg_controls_df.drop('state', axis = 1)\n",
    "    \n",
    "    return batch_neg_controls_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T11:52:41.464222Z",
     "start_time": "2020-12-02T11:52:41.456223Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "675/45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T11:53:11.823359Z",
     "start_time": "2020-12-02T11:53:11.819362Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "45/15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T20:32:15.681071Z",
     "start_time": "2020-06-25T20:32:15.672072Z"
    }
   },
   "outputs": [],
   "source": [
    "# def batch_negative_controls(ramdomized_sample_df, batch_df, negControls_master, unrepeated_negControls, \n",
    "#                           number_plates, rand_state, previous_batch_negControls = None):\n",
    "#     ''' This funtions select batch negative controls, then appends a repeated list of pids \n",
    "#         Then merges with the samples from 2020. This will be the input for th eoptimization function'''\n",
    "    \n",
    "#     #Remove previous batches negative controls from master list, if applicable\n",
    "#     if previous_batch_negControls.empty:\n",
    "#         negControls_master = negControls_master\n",
    "        \n",
    "#     else:\n",
    "#         keep = pd.DataFrame(set(negControls_master.biobank_id) - set(previous_batch_negControls.biobank_id)).rename(columns = {0:'biobank_id'}) \n",
    "#         negControls_master = pd.merge(negControls_master, keep, how = 'inner')\n",
    "\n",
    "    \n",
    "#     #match negative controls on state\n",
    "#     neg_controls_df= pd.merge(negControls_master[['biobank_id', 'participant_id','state', 'DateBloodSampleCollected']].drop_duplicates(), \n",
    "#                                 batch_df[['state']].drop_duplicates()).drop('state', axis = 1).drop_duplicates()#.reset_index()\n",
    "\n",
    "#     ## randomly select the batch negative controls\n",
    "#     batch_neg_controls_df = neg_controls_df.sample(n = int(unrepeated_negControls), \n",
    "#                                                 random_state = rand_state).reset_index().drop('index', axis = 1)\n",
    " \n",
    "#     ### Assign negative controls to plates\n",
    "#     batch_neg_controls_df['plate']= int()\n",
    "#     batch_neg_controls_df['plate']= range(1,int(unrepeated_negControls)+1)\n",
    "   \n",
    "#     repeat = batch_neg_controls_df\n",
    "#     repeat['plate']= int()\n",
    "#     repeat['plate']= range(int(unrepeated_negControls)+2, number_plates+2)\n",
    " \n",
    "#     batch_controls_repeated = batch_neg_controls_df.append(repeat)\n",
    "      \n",
    "#     batch_controls_repeated['negative control'] = 'Yes'\n",
    "#     batch_controls_repeated['positive control'] = 'No'\n",
    "#     batch_controls_repeated['location'] = 'No'\n",
    "\n",
    "#     #checks\n",
    "#     print('unique pids:' + str(batch_controls_repeated.biobank_id.nunique()))\n",
    "#     print('shape:' + str(batch_controls_repeated.shape))\n",
    "    \n",
    "#     return batch_controls_repeated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `batch_positive_controls()`:  Function to add positive controls \n",
    "\n",
    "\n",
    "'*  *'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T18:27:37.381386Z",
     "start_time": "2020-10-08T18:27:37.374384Z"
    }
   },
   "outputs": [],
   "source": [
    "def batch_positive_controls(pos_controls_df, number_plates, rand_state, aliquots_needed):\n",
    "    '''Function to get positive controls '''\n",
    "\n",
    "    # choose n samples from positive controls, randomly from high/med/low\n",
    "    pos_controls = pos_controls_df.drop_duplicates()\n",
    "     \n",
    "    pos_controls = pos_controls.sample(n = int(number_plates/2), random_state= rand_state)\n",
    "#    pos_controls = pd.DataFrame(pos_controls.append(pos_controls))\n",
    "  #  display(pos_controls.shape)\n",
    "    \n",
    "    ## QC - chheck volume\n",
    "    check = pd.merge(pos_controls, pos_controls_df.drop_duplicates())\n",
    "    print('checking batch positive control volume per sample:')\n",
    "    display(check.iloc[:,1].sum()/aliquots_needed)\n",
    "\n",
    "    pos_controls = pos_controls.sort_values('Sample ID', ascending = True)\n",
    "    pos_controls2 = pos_controls.sort_values('Sample ID', ascending = False) # for duplication\n",
    "    pos_controls_DF = pd.concat([pos_controls,pos_controls2])\n",
    "\n",
    "    \n",
    "    ### Assign POS controls to plates\n",
    "    pos_controls_DF['plate']= int()\n",
    "    pos_controls_DF['plate']= range(1,int(number_plates)+1)\n",
    "    \n",
    "    pos_controls_DF['Positive Control']= 'Yes'\n",
    "    pos_controls_DF['Negative Control']= 'No'\n",
    " \n",
    "    return pos_controls_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `final_deliverable()`:Function to get final deliverable\n",
    "Put the sample, positive controls and negative controls together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T18:56:33.052407Z",
     "start_time": "2020-10-08T18:56:33.042401Z"
    }
   },
   "outputs": [],
   "source": [
    "def final_deliverable(optimized_seq, neg_controls, pos_controls, bid_fieldname):\n",
    "    '''Function to add all together and return final deliverable'''\n",
    "\n",
    "    Serology_final_dataset = pd.concat([optimized_seq, neg_controls], sort=True)\n",
    "    Serology_final_dataset = pd.concat([Serology_final_dataset, pos_controls], sort=True)\n",
    "    \n",
    "    Serology_final_dataset = Serology_final_dataset.rename(columns = {'Sample ID':'Positive Control ID'})\n",
    "    \n",
    "#     Serology_final_dataset = Serology_final_dataset[['biobank_id', 'serology_id', 'Sample ID', 'Description', 'Position in Rack', 'Rack', 'Sequence',\n",
    "#                         'location', 'negative control', 'positive control','plate']]\n",
    "\n",
    "    print(colored('QC Number of positive, negative and test samples before sending final file: ', 'white'))\n",
    "    display(Serology_final_dataset.head())\n",
    "\n",
    "    negs = Serology_final_dataset[Serology_final_dataset['Negative Control'] == 'Yes']\n",
    "    n_negs = negs[bid_fieldname].nunique()\n",
    "    testSamples =Serology_final_dataset[(Serology_final_dataset['Negative Control'] == 'No') &\n",
    "                                        (Serology_final_dataset['Positive Control'] == 'No')]\n",
    "    n_testSamples = testSamples[bid_fieldname].nunique()\n",
    "    \n",
    "    if 'Positive Control ID' in Serology_final_dataset.columns:\n",
    "        n_pos = Serology_final_dataset[Serology_final_dataset['Positive Control'] == 'Yes']['Positive Control ID'].nunique()\n",
    "        total_sample = n_pos+n_negs+n_testSamples\n",
    "\n",
    "    else:\n",
    "        n_pos = Serology_final_dataset[Serology_final_dataset['Positive Control'] == 'Yes'][bid_fieldname].nunique()\n",
    "        total_sample = Serology_final_dataset[bid_fieldname].nunique()\n",
    "    \n",
    "    print(colored('Total Unique Non Control Samples: ' + str(n_testSamples), 'magenta')) \n",
    "    print(colored('Total Unique Negative Controls: ' + str(n_negs), 'magenta')) \n",
    "    print(colored('Total Unique Positive Controls: ' + str(n_pos), 'magenta')) \n",
    "    print(colored('Total Unique Samples Tested (including controls): ' + str(total_sample), 'blue')) \n",
    "    \n",
    "    print(colored('Date Blood Sample Collected Max: ' + str(testSamples.DateBloodSampleCollected.max()), 'green')) \n",
    "    print(colored('Date Blood Sample Collected Min: ' + str(testSamples.DateBloodSampleCollected.min()), 'green'))\n",
    "    print(colored('Date Negative Control Blood Sample Collected Max: ' + str(negs.DateBloodSampleCollected.max()), 'green')) \n",
    "    print(colored('Date Negative Control Blood Sample Collected Min: ' + str(negs.DateBloodSampleCollected.min()), 'green'))\n",
    "   \n",
    "    Serology_final_dataset[['biobank_id','plate', 'Positive Control ID']].drop_duplicates().sort_values('plate').groupby('plate').nunique()\n",
    "    \n",
    "    return Serology_final_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `get_dist()`: Function to Check the distributions of datasets by a specified variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T16:51:54.562234Z",
     "start_time": "2020-06-25T16:51:54.556233Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_dist(DF, dist_var, group = None, groupnumber = None):\n",
    "    '''group determines whether the distribution is to be done by plate or on the entire dataset.\n",
    "       dist_var is the variable for which we check the distribution -- ie race, state \n",
    "       if group is 'plate', then, group number is the plate number'''\n",
    "            \n",
    "    if group == None:\n",
    "        df = pd.DataFrame(DF[['participant_id', dist_var]].drop_duplicates()[dist_var].value_counts())\n",
    "        df['%ofTheGroup'] = (df[dist_var]/DF.participant_id.nunique())*100\n",
    "        \n",
    "    else:        \n",
    "        df1 = DF[DF[group] == groupnumber] \n",
    "        df = pd.DataFrame(df1[['participant_id', dist_var]].drop_duplicates()[dist_var].value_counts())\n",
    "        df['%ofTheGroup'] = (df[dist_var]/df1.participant_id.nunique())*100\n",
    "\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `QC_batch_numbers` Function to QC the numbers in the final batch/list deliverable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T21:33:45.004082Z",
     "start_time": "2020-11-30T21:33:44.996077Z"
    }
   },
   "outputs": [],
   "source": [
    "def QC_batch_numbers(DF, bid_fieldname):\n",
    "    ''' Function to check the bumber of positive, negative and test samples before sending final file.'''\n",
    "    \n",
    "    DF.DateBloodSampleCollected = pd.to_datetime(DF.DateBloodSampleCollected)\n",
    "    specimens = DF['Specimen ID'].nunique()\n",
    "    negs = DF[DF['Negative Control'] == 'Yes']\n",
    "    n_negs = negs[bid_fieldname].nunique()\n",
    "    testSamples =DF[(DF['Negative Control'] == 'No') &\n",
    "                                        (DF['Positive Control'] == 'No')]\n",
    "    n_testSamples = testSamples[bid_fieldname].nunique()\n",
    "    \n",
    "    if 'Positive Control ID' in DF.columns:\n",
    "        n_pos = DF[DF['Positive Control'] == 'Yes']['Positive Control ID'].nunique()\n",
    "        total_sample = n_pos+n_negs+n_testSamples\n",
    "\n",
    "    else:\n",
    "        n_pos = DF[DF['Positive Control'] == 'Yes'][bid_fieldname].nunique()\n",
    "        total_sample = DF[bid_fieldname].nunique()\n",
    "    \n",
    "    print(colored('Total Non Control Samples: ' + str(n_testSamples), 'magenta')) \n",
    "    print(colored('Total Unique Negative Controls: ' + str(n_negs), 'magenta')) \n",
    "    print(colored('Total Unique Positive Controls: ' + str(n_pos), 'magenta')) \n",
    "    print(colored('Total Unique Samples Tested (including controls): ' + str(total_sample), 'blue'))\n",
    "    print(colored('Total Unique Samples/Specimen IDs(including controls): ' + str(specimens), 'blue'))\n",
    "    \n",
    "    print(colored('Date Blood Sample Collected Max: ' + str(testSamples.DateBloodSampleCollected.max()), 'green')) \n",
    "    print(colored('Date Blood Sample Collected Min: ' + str(testSamples.DateBloodSampleCollected.min()), 'green'))\n",
    "    print(colored('Any Null Blodd Sample Dates in the non controls?: ' + str(testSamples[testSamples.DateBloodSampleCollected.isnull()][bid_fieldname].nunique()), \n",
    "                                                                             'green')) \n",
    "    \n",
    "    print(colored('\\nDate Negative Control Blood Sample Collected Max: ' + str(negs.DateBloodSampleCollected.max()), 'green')) \n",
    "    print(colored('Date Negative Control Blood Sample Collected Min: ' + str(negs.DateBloodSampleCollected.min()), 'green'))\n",
    "   \n",
    "    #print(colored('N States: ' + str(testSamples.state.nunique()), 'yellow')) \n",
    "#     print(colored('N States Negative Controls: ' + str(negs.state.nunique()), 'yellow')) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `get_specimens_counts()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T21:01:13.047620Z",
     "start_time": "2020-12-02T21:01:13.037620Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_specimens_counts(DF, which_field, plated = 'Yes'):\n",
    "    ''' Function to check the bumber of positive, negative and test samples numbers.'''\n",
    "    \n",
    "    print(colored('Counts for the '+str(which_field)+' field:', 'red'))\n",
    "    \n",
    "    negs = DF[DF['Negative Control'] == 'Yes']\n",
    "    n_negs = negs[which_field].nunique()\n",
    "    \n",
    "    testSamples =DF[(DF['Negative Control'] == 'No') & (DF['Positive Control'] == 'No')]\n",
    "    n_testSamples = testSamples[which_field].nunique()\n",
    "    \n",
    "    count1 = int(testSamples[which_field].count())+ int(negs[which_field].count())\n",
    "    \n",
    "    pos = DF[DF['Positive Control'] == 'Yes']\n",
    "    if 'Positive Control ID' in DF.columns:      \n",
    "        n_pos = pos['Positive Control ID'].nunique()\n",
    "        count_pos = pos['Positive Control ID'].count()\n",
    "        total_sample = n_pos+n_negs+n_testSamples\n",
    "\n",
    "    else:\n",
    "        n_pos = pos[which_field].nunique()\n",
    "        count_pos = pos[which_field].count()\n",
    "        total_sample = DF[which_field].nunique()\n",
    "    \n",
    "    print(colored(' \\nN Unique Non Controls: ' + str(n_testSamples), 'magenta')) \n",
    "    print(colored(' Count Non Controls: ' + str(testSamples[which_field].count()), 'magenta')) \n",
    "    print(colored('Date Non Controls Blood Sample Collected Max: ' + str(testSamples.DateBloodSampleCollected.max()), 'magenta')) \n",
    "    print(colored('Date Non Controls Blood Sample Collected Min: ' + str(testSamples.DateBloodSampleCollected.min()), 'magenta'))\n",
    "    \n",
    "    print(colored(' \\nN Unique Negative Controls: ' + str(n_negs), 'green')) \n",
    "    print(colored(' Count Negative Controls: ' + str(negs[which_field].count()), 'green'))\n",
    "    print(colored('Date Neg Controls Blood Sample Collected Max: ' + str(negs.DateBloodSampleCollected.max()), 'green')) \n",
    "    print(colored('Date Neg Controls Blood Sample Collected Min: ' + str(negs.DateBloodSampleCollected.min()), 'green'))\n",
    "\n",
    "    \n",
    "    print(colored(' \\nN Unique Positive Controls: ' + str(n_pos), 'blue')) \n",
    "    print(colored(' Count Positive Controls: ' + str(count_pos), 'blue')) \n",
    "    print(colored('Date Pos Controls Blood Sample Collected Max: ' + str(pos.DateBloodSampleCollected.max()), 'blue')) \n",
    "    print(colored('Date Pos Controls Blood Sample Collected Min: ' + str(pos.DateBloodSampleCollected.min()), 'blue'))\n",
    "    \n",
    "    print(colored(' \\nN Unique All Samples (including controls): ' + str(total_sample), 'yellow'))\n",
    "    print(colored(' Count All Samples (including controls): ' + str(int(count1+count_pos)), 'yellow')) \n",
    "    \n",
    "    \n",
    "    if plated == 'Yes':\n",
    "        print(colored(' \\nN Unique Plates: ' + str(DF.plate.nunique()), 'magenta')) \n",
    "        print(colored(' Count Plates: ' + str(DF.plate.count()), 'magenta'))\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "383.906px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
