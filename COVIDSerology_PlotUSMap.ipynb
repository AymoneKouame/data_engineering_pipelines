{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T22:55:46.763013Z",
     "start_time": "2021-06-03T22:55:40.539140Z"
    }
   },
   "outputs": [],
   "source": [
    "%run ../setup.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-21T18:44:31.328909Z",
     "start_time": "2021-05-21T18:44:31.308907Z"
    }
   },
   "outputs": [],
   "source": [
    "%run C:\\Users\\kouamea\\CONNECTIONS\\plots.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T22:55:50.928075Z",
     "start_time": "2021-06-03T22:55:50.824077Z"
    }
   },
   "outputs": [],
   "source": [
    "data_directory = '../DATA\\\\DSC2\\\\'\n",
    "\n",
    "state_data = pd.read_csv(data_directory+'/Non Controls States1.12.21.csv').iloc[:,1:]\n",
    "state_data.head()# = state_data.groupby('State').nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T22:55:51.243096Z",
     "start_time": "2021-06-03T22:55:51.230091Z"
    }
   },
   "outputs": [],
   "source": [
    "state_data_noAl_Hw = state_data[(state_data.State != 'Alaska') &(state_data.State != 'Hawaii')]\n",
    "state_data_noAl_Hw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T22:56:26.565500Z",
     "start_time": "2021-06-03T22:56:26.182475Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load plotnine_map_codes\n",
    "\n",
    "import pandas as pd\n",
    "states = pd.read_csv('C:/Users\\kouamea\\CONNECTIONS\\states.csv').rename(columns = {'region':'State'})#[['ID','X','Y']]\n",
    "states = states.rename(columns = {'full':'State', 'x':'long','y':'lat'})[['State','long','lat', 'group']]\n",
    "states.State = [i.lower() for i in states.State]\n",
    "#terr = pd.read_csv('C:/Users\\kouamea\\CONNECTIONS\\states\terr.csv').rename(columns = {'region':'State'})#[['ID','X','Y']]\n",
    "\n",
    "#states_and_terr = states#.rename(columns = {'region':'State'})\n",
    "#states.head()\n",
    "\n",
    "def centroid(DF):\n",
    "    \n",
    "    centroids_df = pd.DataFrame(columns = ['State','x','y'])\n",
    "    for s in DF.State.unique():\n",
    "       # print(s)\n",
    "        df = DF[DF.State == s]\n",
    "        x_list = [x for x in df['long']]\n",
    "        y_list = [x for x in df['lat']]\n",
    "        l = len(df)\n",
    "        #print(l)\n",
    "        x = sum(x_list) / l\n",
    "        #print(x)\n",
    "        y = sum(y_list) / l\n",
    "        df = pd.DataFrame({'State':[s], 'x':[x],'y':[y]})\n",
    "        \n",
    "        centroids_df = pd.concat([centroids_df, df]).drop_duplicates()\n",
    "    #display(centroids_df)\n",
    "        \n",
    "    return(centroids_df)\n",
    "\n",
    "states_centroids = centroid(states[['State','long','lat']])\n",
    "states_centroids = centroid(states[['State','long','lat']])\n",
    "states_centroids.head()\n",
    "\n",
    "### adding centroids for us terriories AND no state data. so i can annotate on map\n",
    "\n",
    "us_terr_x = float(states_centroids[states_centroids['State'] == 'arizona']['x'].values)\n",
    "us_terr_y = float(states_centroids[states_centroids['State'] == 'alaska']['y'].values)\n",
    "\n",
    "states_centroids_terr = pd.DataFrame({'State': ['US Territories', 'No State Data'], \n",
    "                                      'x': [us_terr_x,us_terr_x-10000], \n",
    "                                      'y': [us_terr_y-100000,us_terr_y-150000]})\n",
    "states_centroids_terr\n",
    "\n",
    "states_centroids = pd.concat([states_centroids_terr, states_centroids])\n",
    "#states_centroids.head()\n",
    "\n",
    "def get_map_data(state_data):\n",
    "    \n",
    "    #############################################################\n",
    "    df = state_data[['pid','State']].drop_duplicates()\n",
    "    df.State = [i.lower() for i in df.State]\n",
    "    df = df.groupby('State', as_index = False).nunique()\n",
    "    df1 = df.merge(states)\n",
    "\n",
    "    #######################################################\n",
    "    df2 = df\n",
    "    df2['pid'] = df2['pid'].fillna(0).astype('int64')\n",
    "    #df2['%'] = [str(round((int(i)/int(1200)*100),1))+'%' for i in df2['pid']]\n",
    "    #df2['%'] = ['('+ str(i)+')' for i in df2['%']]\n",
    "\n",
    "    df2.loc[df2.pid <20, 'pid2'] = '<20'\n",
    "    df2.loc[df2.pid >=20, 'pid2'] = [format(int(i), \"7,d\").strip(' ') for i in df2.loc[df2.pid>=20, 'pid']]\n",
    "    #df2[\"pid2\"]  = [format(int(i), \"7,d\").strip(' ') for i in df2.pid.fillna(0)]\n",
    "    #df2[\"pis2\"]  = [str(df2.loc[i,'pid'])+str(df2.loc[i,'%']) for i in df2.index]\n",
    "\n",
    "    df2 = df2.merge(states_centroids).drop_duplicates()\n",
    "    df2 = df2[~df2.State.isin(['US Territories','No State Data'])]\n",
    "\n",
    "    return df1, df2    \n",
    "\n",
    "dummy_data = pd.DataFrame({'pid':[545,455,788], 'State':['alabama', 'colorado', 'tennessee']})\n",
    "map_df1, map_df2 = get_map_data(dummy_data)\n",
    "\n",
    "\n",
    "import plotnine\n",
    "from plotnine import *\n",
    "def get_map(df1, df2, your_title):   \n",
    "    \n",
    "    #go left\n",
    "    df2.loc[df2.State == 'colorado', 'x']= df2[df2.State == 'colorado']['x']-7000\n",
    "    df2.loc[df2.State == 'nebraska', 'x']= df2[df2.State == 'nebraska']['x']-100000\n",
    "    df2.loc[df2.State == 'north dakota', 'x']= df2[df2.State == 'north dakota']['x']-50000\n",
    "    df2.loc[df2.State == 'south dakota', 'x']= df2[df2.State == 'south dakota']['x']-100000\n",
    "    df2.loc[df2.State == 'kansas', 'x']= df2[df2.State == 'kansas']['x']-100000\n",
    "    df2.loc[df2.State == 'arkansas', 'x']= df2[df2.State == 'arkansas']['x']-9000\n",
    "    df2.loc[df2.State == 'minnesota', 'x']= df2[df2.State == 'minnesota']['x']-50000\n",
    "    df2.loc[df2.State == 'missouri', 'x']= df2[df2.State == 'missouri']['x']-6000\n",
    "    df2.loc[df2.State == 'michigan', 'x']= df2[df2.State == 'michigan']['x']-10000\n",
    "    df2.loc[df2.State == 'new york', 'x']= df2[df2.State == 'new york']['x']-10000\n",
    "    df2.loc[df2.State == 'massachusetts', 'x']= df2[df2.State == 'massachusetts']['x']-90000\n",
    "    df2.loc[df2.State == 'district of columbia', 'x']= df2[df2.State == 'district of columbia']['x']-80000\n",
    "    df2.loc[df2.State == 'hawaii', 'x']= df2[df2.State == 'hawaii']['x']-40000\n",
    "    df2.loc[df2.State == 'maryland', 'x']= df2[df2.State == 'maryland']['x']-40000\n",
    " \n",
    "    #go right\n",
    "    df2.loc[df2.State == 'montana', 'x']= df2[df2.State == 'montana']['x']+150000\n",
    "    df2.loc[df2.State == 'washington', 'x']= df2[df2.State == 'washington']['x']+120000\n",
    "    df2.loc[df2.State == 'arizona', 'x']= df2[df2.State == 'arizona']['x']+180000\n",
    "    df2.loc[df2.State == 'florida', 'x']= df2[df2.State == 'florida']['x']+140000\n",
    "    df2.loc[df2.State == 'south carolina', 'x']= df2[df2.State == 'south carolina']['x']+100000\n",
    "    df2.loc[df2.State == 'north carolina', 'x']= df2[df2.State == 'north carolina']['x']+100000\n",
    "    df2.loc[df2.State == 'michigan', 'x']= df2[df2.State == 'michigan']['x']+110000\n",
    "    df2.loc[df2.State == 'new jersey', 'x']= df2[df2.State == 'new jersey']['x']+120000\n",
    "    df2.loc[df2.State == 'delaware', 'x']= df2[df2.State == 'delaware']['x']+120000\n",
    "    df2.loc[df2.State == 'rhode island', 'x']= df2[df2.State == 'rhode island']['x']+50000\n",
    "    df2.loc[df2.State == 'hawaii', 'x']= df2[df2.State == 'hawaii']['x']+180000\n",
    "    #df2.loc[df2.State == 'massachusetts', 'x']= df2[df2.State == 'massachusetts']['x']+80000\n",
    "    df2.loc[df2.State == 'new hampshire', 'x']= df2[df2.State == 'new hampshire']['x']+10000\n",
    "#     df2.loc[df2.State == 'minnesota', 'x']= df2[df2.State == 'minnesota']['x']-6000\n",
    "\n",
    "    \n",
    "    ## go up\n",
    "    df2.loc[df2.State == 'nevada', 'y']= df2[df2.State == 'nevada']['y']+100000\n",
    "    df2.loc[df2.State == 'oklahoma', 'y']= df2[df2.State == 'oklahoma']['y']+1000\n",
    "    df2.loc[df2.State == 'alabama', 'y']= df2[df2.State == 'alabama']['y']+3000\n",
    "    df2.loc[df2.State == 'mississippi', 'y']= df2[df2.State == 'mississippi']['y']+10000\n",
    "    df2.loc[df2.State == 'maryland', 'y']= df2[df2.State == 'maryland']['y']+40000\n",
    "    df2.loc[df2.State == 'new york', 'y']= df2[df2.State == 'new york']['y']+30000\n",
    "    df2.loc[df2.State == 'vermont', 'y']= df2[df2.State == 'vermont']['y']+80000\n",
    "    df2.loc[df2.State == 'connecticut', 'y']= df2[df2.State == 'connecticut']['y']+30000\n",
    "    df2.loc[df2.State == 'alaska', 'y']= df2[df2.State == 'alaska']['y']+200000\n",
    "    df2.loc[df2.State == 'indiana', 'y']= df2[df2.State == 'indiana']['y']+100000\n",
    "    #df2.loc[df2.State == 'massachusetts', 'y']= df2[df2.State == 'massachusetts']['y']+10000\n",
    "    \n",
    "    ## go down\n",
    "    df2.loc[df2.State == 'oregon', 'y']= df2[df2.State == 'oregon']['y']-100000\n",
    "    df2.loc[df2.State == 'idaho', 'y']= df2[df2.State == 'idaho']['y']-100000\n",
    "    df2.loc[df2.State == 'kentucky', 'y']= df2[df2.State == 'kentucky']['y']-30000\n",
    "    df2.loc[df2.State == 'michigan', 'y']= df2[df2.State == 'michigan']['y']-180000\n",
    "    df2.loc[df2.State == 'delaware', 'y']= df2[df2.State == 'delaware']['y']-80000\n",
    "    df2.loc[df2.State == 'virginia', 'y']= df2[df2.State == 'virginia']['y']-30000\n",
    "    df2.loc[df2.State == 'district of columbia', 'y']= df2[df2.State == 'district of columbia']['y']-80000\n",
    "    df2.loc[df2.State == 'rhode island', 'y']= df2[df2.State == 'rhode island']['y']-50000\n",
    "    df2.loc[df2.State == 'hawaii', 'y']= df2[df2.State == 'hawaii']['y']-150000\n",
    "\n",
    "\n",
    "#   ###################################################################################\n",
    "    plotnine.options.figure_size = (14,10) #w,l\n",
    "\n",
    "    #lowest = format(min(df1.pid), \"7,d\").strip(' ')\n",
    "    #highest = format(max(df1.pid), \"7,d\").strip(' ')\n",
    "\n",
    "    ###################################################################################\n",
    "    plot =  (ggplot()\n",
    "            + geom_polygon(df1, aes(x = 'long', y = 'lat',group = 'group',\n",
    "                                    fill = 'pid'), colour = \"black\")\n",
    "\n",
    "            +theme_classic()\n",
    "            + theme(axis_ticks= element_blank(), axis_line= element_blank(),\n",
    "                    axis_text= element_blank(),\n",
    "                    text= element_text(family = 'Arial')\n",
    "                   )\n",
    "\n",
    "            + scale_fill_gradient(#low = 'aliceblue', high = 'skyblue', \n",
    "                                  low = 'white', high = 'lightgray',\n",
    "                                  #name = 'test', \n",
    "                                  #breaks = [min(df1.pid), \n",
    "                                   #         max(df1.pid)]\n",
    "                \n",
    "                                    #breaks = [1,1]\n",
    "                                  )\n",
    "             +theme( \n",
    "                # legend_text = element_text(size= 12, va = 'bottom', color = 'black', \n",
    "                 #                           fontweight = 'normal'), \n",
    "                # legend_title= element_text(size=8, color = 'black', fontweight = 'normal'),\n",
    "                 #legend_box= element_rect(size = 12),\n",
    "                # legend_title_align=\"center\", legend_direction= 'horizontal', legend_position= 'bottom' #'bottom'\n",
    "                    legend_position = 'none')\n",
    "             \n",
    "\n",
    "            + geom_text(df2[['pid2','x','y']].drop_duplicates(),\n",
    "                    aes(x = 'x', y = 'y', label = 'pid2'), size = 10, color = 'black',\n",
    "                    #fontweight = 'demibold'\n",
    "                       ) \n",
    "             \n",
    "            #+ geom_text(df2[['x','y','%']].drop_duplicates(),\n",
    "            #        aes(x = 'x', y = 'y', label = \"%\"), size = 12) \n",
    "\n",
    "             \n",
    "             \n",
    "            + theme(title= element_text(size = 12, color = 'black'\n",
    "                                   #,fontweight='bold'\n",
    "                                        ,va = 'center_baseline'\n",
    "                                      # ,ha = 'right'\n",
    "                                       ))  \n",
    "\n",
    "             + labs(x = '', y = '', title = your_title)\n",
    "\n",
    "            )\n",
    "    \n",
    "    df3 = df2[df2.State.isin(['US Territories','No State Data'])]\n",
    "    #display(df3)\n",
    "    if df3.empty == False:\n",
    "        display(df3)    \n",
    "        plot + geom_text(df3[['pid','x','y']].drop_duplicates(),\n",
    "                      aes(x = 'x', y = 'y', label = 'pid'), size = 10, color = 'black'\n",
    "                     ,fontweight = 'semibold'\n",
    "                     ) \n",
    "\n",
    "    \n",
    "    plot.save(data_directory+'Serology PAPER MAP2.tif', dpi = 800, limitsize = False)\n",
    "\n",
    "    return plot#, df2\n",
    "\n",
    "#plot = get_map(map_df1, map_df2)\n",
    "#plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-21T20:22:13.910186Z",
     "start_time": "2021-05-21T20:22:13.908183Z"
    }
   },
   "outputs": [],
   "source": [
    "#map_df1, map_df2 = get_map_data(state_data.rename(columns = {'Biobank ID':'pid'}))\n",
    "#map_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T22:57:44.873594Z",
     "start_time": "2021-06-03T22:57:42.811474Z"
    }
   },
   "outputs": [],
   "source": [
    "## with alaska and hawai\n",
    "map_df1, map_df2 = get_map_data(state_data.rename(columns = {'Biobank ID':'pid'}))\n",
    "plot = get_map(map_df1, map_df2\n",
    "               ,your_title = \n",
    "               '''Figure1: The number of All of Us participants with blood specimens collected January 2 to March 18, 2020 \n",
    "               \\navailable for serologic testing from each state, N=24,079''')\n",
    "\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-21T20:23:05.023171Z",
     "start_time": "2021-05-21T20:23:03.324062Z"
    }
   },
   "outputs": [],
   "source": [
    "## with alaska and hawai\n",
    "map_df1, map_df2 = get_map_data(state_data_noAl_Hw.rename(columns = {'Biobank ID':'pid'}))\n",
    "plot = get_map(map_df1, map_df2\n",
    "               ,your_title = \n",
    "               '''Figure1: The number of All of Us participants with blood specimens collected January 2 to March 18, 2020 \n",
    "               \\navailable for serologic testing from each state, N=24,079''')\n",
    "plot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
