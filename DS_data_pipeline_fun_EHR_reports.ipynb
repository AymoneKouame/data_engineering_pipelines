{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to save a file to bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import os\n",
    "\n",
    "def upload_blob(source_file_name, destination_blob_name):\n",
    "    \"\"\"Uploads a file to the bucket.\"\"\"\n",
    "    bucket_name = os.getenv('WORKSPACE_BUCKET').replace('gs://','')\n",
    "    \n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name = bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "    blob.upload_from_filename(source_file_name)\n",
    "\n",
    "    print(\n",
    "        \"File {} uploaded to {}.\".format(\n",
    "            source_file_name, destination_blob_name\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EHR Notebook Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T15:15:54.185771Z",
     "start_time": "2022-10-20T15:15:54.178775Z"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile ehr_report.py\n",
    "\n",
    "# For operating system operations\n",
    "import os\n",
    "\n",
    "# For Data Manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import statistics\n",
    "import datetime \n",
    "\n",
    "# For Data Visualization\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "###############\n",
    "dataset = os.getenv('WORKSPACE_CDR')\n",
    "\n",
    "############################################## DATA COLLECTION #####################################################\n",
    "\n",
    "def historic_ehr(dataset = dataset):\n",
    "        \n",
    "    def ehr_by_domain(domain, start_date_field, end_date_field, dataset, table, table_id, cutoff):\n",
    "\n",
    "        concept_id = domain.lower()+'_concept_id'\n",
    "            #print(domain, start_date_field, end_date_field, table, table_id, concept_id)\n",
    "        df = pd.read_gbq(f''' SELECT DISTINCT person_id\n",
    "                                    , '{domain}' as ehr_domain\n",
    "                                    , src_id AS ehr_site\n",
    "                                    , vocabulary_id as vocabulary\n",
    "                                    , MIN({start_date_field}) AS start_date\n",
    "                                    , CASE WHEN MAX({end_date_field}) IS NULL THEN \"{cutoff}\"\n",
    "                                        ELSE MAX({end_date_field}) END AS end_date\n",
    "\n",
    "                                FROM `{dataset}.{table}`\n",
    "                                LEFT JOIN `{dataset}.{table}_ext` USING({table_id})\n",
    "                                JOIN `{dataset}.concept` on concept_id = {concept_id}\n",
    "                                WHERE LOWER(src_id) LIKE 'ehr site%'\n",
    "                                GROUP BY 1,2,3,4\n",
    "                                ''')\n",
    "\n",
    "        return df\n",
    "        ##########################################################################\n",
    "\n",
    "    # setting variables\n",
    "    tables = ['measurement', 'condition_occurrence','device_exposure','drug_exposure'\n",
    "                  ,'observation','procedure_occurrence', 'visit_occurrence']\n",
    "    start_end_date_fields = [['measurement_date', 'measurement_date']\n",
    "                                 , ['condition_start_date','condition_end_date']\n",
    "                                 , ['device_exposure_start_date','device_exposure_end_date']\n",
    "                                 , ['drug_exposure_start_date','drug_exposure_end_date']\n",
    "                                 , ['observation_date','observation_date']\n",
    "                                 , ['procedure_date','procedure_date']\n",
    "                                 , ['visit_start_date','visit_end_date']\n",
    "                                ]\n",
    "    domains = ['Measurement', 'Condition','Device','Drug', 'Observation','Procedure', 'Visit']\n",
    "    table_ids = ['measurement_id', 'condition_occurrence_id','device_exposure_id', 'drug_exposure_id'\n",
    "                     ,'observation_id', 'procedure_occurrence_id','visit_occurrence_id']\n",
    "\n",
    "\n",
    "    ehr_cutoff_date = pd.read_gbq(f'''SELECT ehr_cutoff_date  FROM `{dataset}._cdr_metadata`''')\n",
    "    ehr_cutoff =str(ehr_cutoff_date.ehr_cutoff_date[0])   \n",
    "        \n",
    "    historic_ehr_raw = pd.DataFrame()\n",
    "        \n",
    "    for i in range(len(tables)):\n",
    "        df = ehr_by_domain(domain = domains[i]\n",
    "                                , start_date_field = start_end_date_fields[i][0]+'time'\n",
    "                                , end_date_field = start_end_date_fields[i][1]+'time'\n",
    "                                , dataset = dataset\n",
    "                                , table = tables[i], table_id = table_ids[i]\n",
    "                                , cutoff = ehr_cutoff)\n",
    "        historic_ehr_raw = pd.concat([historic_ehr_raw, df])\n",
    "\n",
    "    historic_overall = historic_ehr_raw.copy()\n",
    "    historic_overall['ehr_domain'] = 'Any EHR'\n",
    "    historic_overall = historic_overall.drop_duplicates()#.groupby(['person_id','ehr_domain'], as_index= False).min()\n",
    "    historic_ehr = pd.concat([historic_ehr_raw, historic_overall])\n",
    "\n",
    "    return historic_ehr\n",
    "    \n",
    "def demographics(dataset = dataset): \n",
    "\n",
    "    def clean_demographic_data(demog_df, dataset = dataset):\n",
    "\n",
    "        def clean(df, demographic):\n",
    "            df[demographic] = df[demographic].fillna('Not Specified')\n",
    "\n",
    "            df_multiple_demog = df[['person_id',demographic]].groupby('person_id', as_index = False).nunique()\n",
    "            df_multiple_demog = df_multiple_demog[df_multiple_demog[demographic] >1]['person_id'].unique()  \n",
    "            df.loc[df.person_id.isin(df_multiple_demog), demographic] = 'Multiple Selections'\n",
    "            df = df.drop_duplicates()\n",
    "\n",
    "            df.loc[df[demographic].str.contains(': '), demographic] = \\\n",
    "                        [i.split(': ')[1] for i in df.loc[df[demographic].str.contains(': '), demographic]]\n",
    "\n",
    "            df[demographic] = [i.title() for i in df[demographic]]\n",
    "\n",
    "\n",
    "            new_field_names = {'race ethnicity none of these'.title():'None Of These'\n",
    "                                    , \"sex at birth none of these\".title():'None Of These'\n",
    "                                    , \"none\".title():'None Of These'\n",
    "                                    , 'nhpi'.title():'NHPI (Native Hawaiian and Other Pacific Islander)'\n",
    "                                    , 'mena'.title(): 'MENA (Middle Eastern and North African)'\n",
    "                                    #, 'pmi: skip'.title(): 'Skip'\n",
    "                                   # , 'no matching concept'\n",
    "                                    , 'prefer not to answer'.title(): 'Not Specified'\n",
    "                                    , 'i prefer not to answer'.title(): 'Not Specified'\n",
    "                                    , 'no matching concept'.title(): 'Not Specified'\n",
    "                                    , 'additional options'.title(): 'Not Specified'\n",
    "                                    , 'not man only, not woman only, prefer not to answer, or skipped'.title():'Not Specified'\n",
    "                                  }\n",
    "            df[demographic] = df[demographic].replace(new_field_names)\n",
    "            return df[demographic]\n",
    "\n",
    "        demog_clean_df = demog_df.copy()\n",
    "        for d in demog_df.drop('person_id',1).columns:\n",
    "            if d == 'age_at_cdr':\n",
    "                # create age groups           \n",
    "                demog_clean_df['age_group'] = pd.cut(demog_clean_df[d]\n",
    "                                                         , bins= [18,29,39,49,59,69,79,89,int(demog_clean_df[d].max())]\n",
    "                                                         , labels=[\"18-29\", \"30-39\", \"40-49\", \"50-59\"\n",
    "                                                                   , \"60-69\", \"70-79\", \"80-89\", \"90+\"]\n",
    "                                                         , include_lowest=True)\n",
    "\n",
    "                demog_clean_df = demog_clean_df.drop(d,1)\n",
    "\n",
    "            else:\n",
    "                if 'age' not in d: \n",
    "                    demog_clean_df[d] = clean(df = demog_df, demographic = d)\n",
    "\n",
    "        return demog_clean_df.drop_duplicates()\n",
    "\n",
    "  \n",
    "    # SQL query to get participants demographic data\n",
    "    query = f\"\"\"\n",
    "            SELECT\n",
    "                DISTINCT person_id\n",
    "                , r.race\n",
    "                , LOWER(e.concept_name) AS ethnicity\n",
    "                , CAST(age_at_cdr AS INTEGER) AS age_at_cdr\n",
    "                , s.sex_assigned_at_birth\n",
    "                , gender_identity\n",
    "                , annual_income                                \n",
    "                , educational_attainment   \n",
    "                , employment  \n",
    "\n",
    "            FROM `{dataset}.person`\n",
    "            JOIN `{dataset}.concept` e on e.concept_id = ethnicity_concept_id\n",
    "            LEFT JOIN `{dataset}.cb_search_person` using(person_id)\n",
    "            \n",
    "            LEFT JOIN (SELECT DISTINCT person_id, LOWER(concept_name) as race\n",
    "                      FROM `{dataset}.observation`\n",
    "                      JOIN `{dataset}.concept` on concept_id = value_source_concept_id\n",
    "                      WHERE observation_source_concept_id = 1586140) r using(person_id)\n",
    "                      \n",
    "            LEFT JOIN (SELECT DISTINCT person_id, LOWER(concept_name) as sex_assigned_at_birth\n",
    "                      FROM `{dataset}.observation`\n",
    "                      JOIN `{dataset}.concept` on concept_id = value_source_concept_id\n",
    "                      WHERE observation_source_concept_id = 1585845) s using(person_id)\n",
    "\n",
    "            LEFT JOIN (SELECT DISTINCT person_id, LOWER(concept_name) as annual_income\n",
    "                      FROM `{dataset}.observation`\n",
    "                      JOIN `{dataset}.concept` on concept_id = value_source_concept_id\n",
    "                      WHERE observation_source_concept_id = 1585375) using(person_id)\n",
    "\n",
    "            LEFT JOIN (SELECT DISTINCT person_id, LOWER(concept_name) as gender_identity\n",
    "                      FROM `{dataset}.observation`\n",
    "                      JOIN `{dataset}.concept` on concept_id = value_source_concept_id\n",
    "                      WHERE observation_source_concept_id = 1585838) using(person_id)\n",
    "\n",
    "            LEFT JOIN (SELECT DISTINCT person_id, LOWER(concept_name) as educational_attainment\n",
    "                      FROM `{dataset}.observation` \n",
    "                      JOIN `{dataset}.concept` on concept_id = value_source_concept_id\n",
    "                      where observation_source_concept_id = 1585940) using(person_id) \n",
    "\n",
    "            LEFT JOIN (SELECT DISTINCT person_id, LOWER(concept_name) as employment\n",
    "                      FROM `{dataset}.observation` \n",
    "                      JOIN `{dataset}.concept` on concept_id = value_source_concept_id\n",
    "                      WHERE observation_source_concept_id = 1585952) using(person_id)\n",
    "                      \n",
    "            \"\"\"\n",
    "    raw_demographics_df = pd.read_gbq(query)\n",
    "    demographics_df = clean_demographic_data(raw_demographics_df)\n",
    "\n",
    "    return demographics_df\n",
    "    \n",
    "def ubr(dataset = dataset):\n",
    "    \n",
    "    # Function to query and calculate UBR categories \n",
    "\n",
    "    nulls = ['Null','No matching concept','PMI_Skip','PMI_PreferNotToAnswer', 'AoUDRC_NoneIndicated']\n",
    "    nulls_sql = tuple(nulls)\n",
    "\n",
    "    query = f\"\"\"\n",
    "            SELECT\n",
    "                DISTINCT person_id\n",
    "                , CASE WHEN (race_source_value IS NOT NULL \n",
    "                                AND race_source_value NOT IN ('WhatRaceEthnicity_White')\n",
    "                                AND race_source_value NOT IN {nulls_sql})\n",
    "                            OR (ethnicity_source_value = 'WhatRaceEthnicity_Hispanic') \n",
    "                        THEN 'yes' else 'no' END as ubr_race_ethnicity\n",
    "\n",
    "                , CASE WHEN age_at_consent <18 OR age_at_consent >=65 THEN 'yes' ELSE 'no' END as ubr_age\n",
    "\n",
    "                , CASE WHEN sex_at_birth_source_value IN ('SexAtBirth_Intersex','SexAtBirth_SexAtBirthNoneOfThese')\n",
    "                        THEN 'yes' ELSE 'no' END as ubr_sex_assigned_at_birth\n",
    "\n",
    "                , CASE WHEN income IN ('AnnualIncome_less10k', 'AnnualIncome_10k25k')\n",
    "                        THEN 'yes' ELSE 'no' END as ubr_annual_income\n",
    "\n",
    "                , CASE WHEN education IN ('HighestGrade_NineThroughEleven', 'HighestGrade_FiveThroughEight'\n",
    "                                        , 'HighestGrade_OneThroughFour','HighestGrade_NeverAttended')\n",
    "                        THEN 'yes' ELSE 'no' END as ubr_educational_attainment   \n",
    "\n",
    "                , CASE WHEN \n",
    "                        ((gender_source_value IS NOT NULL\n",
    "                            AND gender_source_value NOT IN {nulls_sql})\n",
    "                            AND gender_source_value NOT IN ('GenderIdentity_Woman', 'GenderIdentity_Man'))\n",
    "\n",
    "                        OR (gender_source_value = 'GenderIdentity_Woman' \n",
    "                            AND sex_at_birth_source_value !='SexAtBirth_Female'\n",
    "                            AND gender_source_value IS NOT NULL\n",
    "                            AND gender_source_value NOT IN {nulls_sql}\n",
    "                            AND sex_at_birth_source_value IS NOT NULL\n",
    "                            AND sex_at_birth_source_value NOT IN {nulls_sql}\n",
    "                            )\n",
    "                        OR (gender_source_value = 'GenderIdentity_Man' \n",
    "                            AND sex_at_birth_source_value !='SexAtBirth_Male'\n",
    "                            AND gender_source_value IS NOT NULL\n",
    "                            AND gender_source_value NOT IN {nulls_sql}\n",
    "                            AND sex_at_birth_source_value IS NOT NULL\n",
    "                            AND sex_at_birth_source_value NOT IN {nulls_sql}\n",
    "                            )\n",
    "                        OR (sexual_orientation IS NOT NULL \n",
    "                            AND sexual_orientation NOT IN {nulls_sql}\n",
    "                            AND sexual_orientation NOT IN ('SexualOrientation_Straight')) \n",
    "                        THEN  'yes' ELSE 'no' END as ubr_sexual_and_gender_minorities\n",
    "\n",
    "\n",
    "\n",
    "            FROM `{dataset}.person`\n",
    "            LEFT JOIN `{dataset}.cb_search_person` using(person_id)\n",
    "            LEFT JOIN (SELECT DISTINCT person_id, value_source_value as income\n",
    "                      FROM `{dataset}.observation` where observation_source_concept_id = 1585375) using(person_id)\n",
    "\n",
    "            LEFT JOIN (SELECT DISTINCT person_id, value_source_value as education\n",
    "                      FROM `{dataset}.observation` where observation_source_concept_id = 1585940) using(person_id) \n",
    "\n",
    "            LEFT JOIN (SELECT DISTINCT person_id, value_source_value as sexual_orientation\n",
    "                      FROM `{dataset}.observation` where observation_source_concept_id = 1585899) using(person_id)\n",
    "                      \n",
    "        \"\"\"\n",
    "    ubr_df = pd.read_gbq(query)\n",
    "\n",
    "    # When multiple sexual orientations or gender identities are chosen\n",
    "    ## assign 'yes' to SGM if the participant meets the UBR SGM criteria for at least one of the \n",
    "    ## sexual orientations or gender identities chosen\n",
    "    for c in ubr_df.drop(['person_id'],1).columns:\n",
    "        multiple_ubrs = ubr_df[['person_id',c]].groupby('person_id').nunique()\n",
    "        multiple_ubrs_pids = multiple_ubrs[multiple_ubrs[c] >1].index.unique()\n",
    "        ubr_df.loc[ubr_df.person_id.isin(multiple_ubrs_pids), c] = 'yes'\n",
    "\n",
    "    ubr_df = ubr_df.drop_duplicates()\n",
    "    ubr_df['ubr_overall'] = (np.where((ubr_df['ubr_race_ethnicity']=='yes') \n",
    "                                          | (ubr_df['ubr_age']=='yes') \n",
    "                                          | (ubr_df['ubr_sex_assigned_at_birth']=='yes')\n",
    "                                          | (ubr_df['ubr_sexual_and_gender_minorities']=='yes') \n",
    "                                          | (ubr_df['ubr_annual_income']=='yes') \n",
    "                                          | (ubr_df['ubr_educational_attainment']=='yes') ,'yes', 'no')\n",
    "                                       )\n",
    "\n",
    "    return ubr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T15:15:54.570699Z",
     "start_time": "2022-10-20T15:15:54.564699Z"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile -a ehr_report.py\n",
    "\n",
    "############################################## DATA WRANGLING AND FORMATTING #####################################################\n",
    "class historic_ehr_by_domain:\n",
    "\n",
    "    def __init__(self, historic_ehr_df, denominator, dataset = dataset):\n",
    "        self.dataset = dataset\n",
    "        self.historic_ehr_df = historic_ehr_df\n",
    "        self.denominator = denominator\n",
    "                \n",
    "    ############################# 1. Historic EHR data by Domains over time, dataframe #############################            \n",
    "    def years_of_data(self, which):\n",
    "        df = self.historic_ehr_df.reset_index(drop = True)\n",
    "        df = df[['person_id','ehr_domain','start_date', 'end_date']].drop_duplicates()\n",
    "        ###\n",
    "        end_date_max = df[['person_id','ehr_domain','end_date']].drop_duplicates()\\\n",
    "                            .groupby(['person_id','ehr_domain'], as_index = False).max()\n",
    "\n",
    "        start_date_min = df[['person_id','ehr_domain','start_date']].drop_duplicates()\\\n",
    "                            .groupby(['person_id','ehr_domain'], as_index = False).min()\n",
    "\n",
    "        df1 = df.drop(['start_date','end_date'],1).merge(start_date_min, 'left')\\\n",
    "                                .merge(end_date_max, 'left').drop_duplicates()\n",
    "\n",
    "        df1['days_diff'] = df1['end_date'] - df1['start_date']\n",
    "        df1['days_diff'] = [abs(i.days) for i in df1['days_diff']] \n",
    "\n",
    "\n",
    "        df1.loc[df1['days_diff'] == 0, 'days_diff'] = 1\n",
    "        \n",
    "        ###\n",
    "        df_years_of_data = df1[['person_id','ehr_domain','days_diff']]\\\n",
    "                                .groupby(['person_id','ehr_domain'], as_index = False).sum()\n",
    "        df_years_of_data['years_of_data'] = df_years_of_data['days_diff']/365\n",
    "        df_years_of_data = df_years_of_data.sort_values('years_of_data')\n",
    "        years_of_data_per_pid = df_years_of_data.drop('days_diff',1)\n",
    "\n",
    "        \n",
    "    ###############################    \n",
    "        \n",
    "        def stats_df(years_of_data_per_pid):\n",
    "            historic_ehr_years_stats = years_of_data_per_pid.groupby(['ehr_domain']).agg({'person_id':'nunique', 'years_of_data'\\\n",
    "                                                                      :['mean','median', 'min','max','std']})\n",
    "\n",
    "            historic_ehr_years_stats.columns = [c[1] for c in historic_ehr_years_stats.columns]\n",
    "            historic_ehr_years_stats[['mean','median','min','max', 'std']] = \\\n",
    "            historic_ehr_years_stats[['mean','median','min','max', 'std']].apply(lambda x: round(x,2)).astype('float64')\n",
    "\n",
    "            historic_ehr_years_stats[['nunique','mean','median','min','max', 'std']] = \\\n",
    "                            format_numbers(historic_ehr_years_stats[['nunique','mean','median','min','max', 'std']])\n",
    "            historic_ehr_years_stats['min'] = historic_ehr_years_stats['min'].replace('0%','0')\n",
    "\n",
    "            name = 'Years of EHR Data Available'\n",
    "            historic_ehr_years_stats.columns = pd.MultiIndex.from_tuples(\n",
    "                                                    [('','N Participants')\n",
    "                                                    ,(f\"{name}\",'Mean')\n",
    "                                                    ,(f\"{name}\",'Median')\n",
    "                                                    ,(f\"{name}\",'Minimum')\n",
    "                                                    ,(f\"{name}\",'Maximun')\n",
    "                                                    ,(f\"{name}\",'Standard Deviation')\n",
    "                                                    ])\n",
    "\n",
    "            return style_df(historic_ehr_years_stats)\n",
    "\n",
    "        def boxplot(years_of_data_per_pid, w = 16, l = 8):\n",
    "\n",
    "            df_plot = years_of_data_per_pid.groupby(['ehr_domain','years_of_data'], as_index = False).nunique()\n",
    "\n",
    "            current_cdr = dataset.split('.')[1]       \n",
    " \n",
    "            sns.set(rc={'figure.figsize':(w, l)})\n",
    "            g = sns.boxplot(data = df_plot\n",
    "                            , x = 'ehr_domain', y = 'years_of_data', hue = 'ehr_domain'\n",
    "                            , medianprops={\"color\": \"red\"}, meanprops={\"color\": \"coral\"}\n",
    "                            , showmeans = True, dodge=False)\n",
    "\n",
    "            g.get_legend().remove()\n",
    "\n",
    "            plt.suptitle(f'''\\nIn the current CDR ({current_cdr}) for N Participants = {'{:,}'.format(self.denominator)}\\n'''\n",
    "                         , size = 16,style='italic')\n",
    "            plt.title('\\nYears of EHR Data Available\\n\\n\\n', size = 20)\n",
    "            plt.xlabel('EHR Domains', size = 16)\n",
    "            plt.ylabel('N Years of Data', size = 16)\n",
    "            plt.xticks(size = 14)\n",
    "            plt.yticks(size = 14)\n",
    "\n",
    "            plt.show()\n",
    "            \n",
    "        if which == 'stats':\n",
    "            figure = stats_df(years_of_data_per_pid)\n",
    "        else:\n",
    "            if which == 'boxplot':\n",
    "                figure = boxplot(years_of_data_per_pid)\n",
    "                \n",
    "        return figure\n",
    "    \n",
    "    ############################# 2. Historic EHR data by Domains over time, plot #############################            \n",
    "    def lineplot(self, add_perc_text = 'yes', rotate_x = 0, plot_start_year = 2010#, save_plot = 'yes'\n",
    "                , w = 16, l = 9):\n",
    "                \n",
    "        def pid_cumcount_by_vars(df, cum_count_by):\n",
    "\n",
    "            cummulative_counts_df = pd.DataFrame()\n",
    "\n",
    "            for d in df[cum_count_by[0]].unique():\n",
    "                #print('\\n'+d)\n",
    "                DF = df[df[cum_count_by[0]] == d][['person_id']+cum_count_by].sort_values(cum_count_by, ascending = True)\n",
    "                DF['cumcount'] = (~DF['person_id'].duplicated()).cumsum()\n",
    "                cum_df = DF.drop('person_id',1).drop_duplicates().reset_index(drop = True)\n",
    "                cum_df[cum_count_by[0]] = d\n",
    "                cum_df = cum_df.sort_values(cum_count_by).groupby(cum_count_by, as_index = False).last() \n",
    "\n",
    "                cummulative_counts_df = pd.concat([cummulative_counts_df, cum_df])\n",
    "\n",
    "            cummulative_counts_df['cumcount'] = cummulative_counts_df['cumcount'].astype('int')\n",
    "\n",
    "            return cummulative_counts_df\n",
    "\n",
    "        #############################################\n",
    "\n",
    "        #Transform\n",
    "        historic_ehr_cum = self.historic_ehr_df.copy()\n",
    "        historic_ehr_cum['start_year'] = [i.year for i in historic_ehr_cum['start_date']]\n",
    "        historic_ehr_cum = pid_cumcount_by_vars(df  = historic_ehr_cum[['person_id','ehr_domain','start_year']].drop_duplicates()\n",
    "                                                , cum_count_by = ['ehr_domain','start_year'])\n",
    "        historic_ehr_cum['cum%'] = round((historic_ehr_cum['cumcount']/self.denominator)*100,2)\n",
    "\n",
    "        historic_ehr_cum_after2000 = historic_ehr_cum[historic_ehr_cum.start_year >= plot_start_year]\n",
    "\n",
    "        df_plot = historic_ehr_cum_after2000.drop(['cumcount'],1)\\\n",
    "                    .pivot(index = ['start_year'], columns = ['ehr_domain']).fillna(0)#.reset_index()\n",
    "        df_plot.columns = [c[1] for c in df_plot.columns]\n",
    "\n",
    "        current_cdr = dataset.split('.')[1]\n",
    "        fig_caption = f'''\\n\\nThis plot represents EHR data availability in the current CDR ({current_cdr}). \n",
    "        The denominator for the percentages is the Total Number of Participants in the current CDR, N = {'{:,}'.format(self.denominator)}.\n",
    "        For better visibility, the plot only displays EHR data growth starting in 2010. '''\n",
    "\n",
    "        #plot\n",
    "        plt.figure(figsize=(w,l), tight_layout=True)\n",
    "        plt.plot(df_plot, 'o-', linewidth=2)\n",
    "\n",
    "        plt.xticks(df_plot.index, size = 13, rotation = rotate_x)\n",
    "        plt.yticks(range(int(historic_ehr_cum_after2000['cum%'].min())\n",
    "                         , int(historic_ehr_cum_after2000['cum%'].max()), 5),size = 13)\n",
    "        plt.gca().yaxis.set_major_formatter(PercentFormatter(decimals=0))\n",
    "        plt.xlabel('Year\\n\\n', size = 16)\n",
    "        plt.ylabel('% of Participants with EHR data', size = 16)\n",
    "        plt.title('\\nHistorical Availability of EHR Records\\n', size = 21)\n",
    "        plt.xticks(size = 14)\n",
    "        plt.yticks(size = 14)\n",
    "        plt.legend(title='EHR Domains', title_fontsize = 14, labels=df_plot.columns, fontsize = 14)\n",
    "        plt.text(statistics.median(df_plot.index), -16\n",
    "             , fig_caption, verticalalignment='bottom',style='italic'\n",
    "             , horizontalalignment='center', color = 'black', size = 14)\n",
    "\n",
    "\n",
    "        if add_perc_text.lower() == 'yes':\n",
    "            min_year = df_plot.index.min()\n",
    "            max_year = df_plot.index.max()\n",
    "\n",
    "            for d in ['Any EHR']:\n",
    "                plt.text(min_year+0.5, df_plot[d][min_year]+2\n",
    "                         , d+' ('+str(int(df_plot[d][min_year]))+'%)',verticalalignment='center'\n",
    "                         ,horizontalalignment='right', color = 'black', size = 12, rotation = 13)\n",
    "                plt.text(max_year-0.0001, df_plot[d][max_year]+1\n",
    "                         , d+' ('+str(int(df_plot[d][max_year]))+'%)',verticalalignment='bottom'\n",
    "                         ,horizontalalignment='center', color = 'black', size = 12)\n",
    "\n",
    "            for d in ['Condition', 'Device', 'Drug'#,'Measurement'\n",
    "                      ,'Observation'#,'Procedure'\n",
    "                      ,'Visit']:\n",
    "                plt.text(min_year-0.1, df_plot[d][min_year]-0.6\n",
    "                         , str(int(df_plot[d][min_year]))+'%',verticalalignment='center'\n",
    "                         ,horizontalalignment='right', color = 'black', size = 12, rotation = 13)\n",
    "\n",
    "            for d in ['Condition', 'Device', 'Drug'#,'Measurement'\n",
    "                      ,'Observation'#,'Procedure','Visit'\n",
    "                     ]:\n",
    "\n",
    "                plt.text(max_year+0.2, df_plot[d][max_year]-1\n",
    "                         , str(int(df_plot[d][max_year]))+'%',verticalalignment='bottom'\n",
    "                         ,horizontalalignment='center', color = 'black', size = 12)\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T15:15:55.600770Z",
     "start_time": "2022-10-20T15:15:55.595765Z"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile -a ehr_report.py\n",
    "\n",
    "class ehr_by:\n",
    "    \n",
    "    def __init__(self, historic_ehr_df, demographics_df, ubr_df):\n",
    "        self.historic_ehr_df = historic_ehr_df\n",
    "        self.demographics_df = demographics_df\n",
    "        self.ubr_df = ubr_df\n",
    "    \n",
    "    \n",
    "    def ehr_by_var(self, which, var = None):\n",
    "        \n",
    "        def ehr_by_var_code(var_df, var, ehr_domain_col = 'ehr_domain', historic_ehr_df = self.historic_ehr_df):        \n",
    "            var_df = var_df[['person_id', var]].drop_duplicates()\n",
    "            all_participants = var_df.copy()\n",
    "            all_participants[ehr_domain_col] = 'All Pids'\n",
    "            denom = int(all_participants.person_id.nunique())\n",
    "\n",
    "            ehr_domain_df = historic_ehr_df[['person_id','ehr_domain']].drop_duplicates()\n",
    "\n",
    "            ehr_by_var_df = ehr_domain_df.merge(var_df, 'left')\n",
    "            ehr_by_var_df[ehr_domain_col] = ehr_by_var_df[ehr_domain_col].fillna('No Data')\n",
    "\n",
    "            ehr_by_var_df = pd.concat([ehr_by_var_df, all_participants])\n",
    "            ehr_by_var_df = ehr_by_var_df\\\n",
    "                                    .groupby([var, ehr_domain_col]).nunique().reset_index()\\\n",
    "                                    .pivot(index = [var], columns = [ehr_domain_col])\n",
    "            ehr_by_var_df.columns = [c[1] for c in ehr_by_var_df.columns]\n",
    "\n",
    "            ## add columns totals\n",
    "            col_total = pd.DataFrame(ehr_by_var_df.sum()).T\n",
    "\n",
    "            col_total[var]= 'TOTAL'; col_total = col_total.set_index(var)\n",
    "            ehr_by_var_df = pd.concat([ehr_by_var_df, col_total])\n",
    "\n",
    "            ehr_by_var_df.columns = [i.title().replace('Ehr','EHR') for i in ehr_by_var_df.columns]\n",
    "\n",
    "            # Adding percentages for the counts\n",
    "            columns_dict = dict()\n",
    "            ehr_by_var_df = ehr_by_var_df.fillna(0).astype('int64')\n",
    "            for n_col in ehr_by_var_df.columns:\n",
    "                #denom = int(denom_df.loc[n_col]['denom'])\n",
    "                ehr_by_var_df[n_col+' %'] = ehr_by_var_df[n_col]/denom\n",
    "                columns_dict[n_col] = n_col+' %'\n",
    "\n",
    "            ehr_by_var_df.index.name =  ehr_by_var_df.index.name.title()\n",
    "            ehr_by_var_df_display = combine_count_and_perc(ehr_by_var_df, columns_dict, drop = True)\n",
    "\n",
    "            if 'UBR' not in ehr_by_var_df_display.index:\n",
    "                ehr_by_var_df_display = format_index_or_col(ehr_by_var_df_display, d_type = var, what = 'index')\n",
    "                ehr_by_var_df_display.index.names = ['Self-reported '+var.title()]\n",
    "\n",
    "            else:\n",
    "                if 'UBR' in ehr_by_var_df_display.index:            \n",
    "                    ehr_by_var_df_display['Diversity Categories'] = var.replace('_',' ').title()\n",
    "                    ehr_by_var_df_display = ehr_by_var_df_display.reset_index()\\\n",
    "                                            .rename(columns = {var.title(): ' '})\n",
    "\n",
    "            return ehr_by_var_df_display\n",
    "\n",
    "        if which.lower() == 'demographic':\n",
    "\n",
    "            ehr_by_var_df = ehr_by_var_code(var = var, var_df = self.demographics_df)\n",
    "\n",
    "        else:\n",
    "            if which.lower() == 'ubr':\n",
    "                #3 ADD TO THE FUNCTIONS\n",
    "                ubr_df1 = self.ubr_df.replace({'yes':'UBR','no':'RBR'})\n",
    "                for col in ubr_df1.drop('person_id',1).columns:\n",
    "                    new_col = col.replace('ubr_','')\n",
    "                    ubr_df1 = ubr_df1.rename(columns = {col:new_col})\n",
    "\n",
    "                ehr_by_var_df = pd.DataFrame()\n",
    "                for var in ubr_df1.drop('person_id',1).columns:\n",
    "                    df0 = ehr_by_var_code(var_df = ubr_df1, var = var)\n",
    "                    df = df0.reindex(df0.index.tolist()+[' ']+[' '])\n",
    "                    df = df.fillna('')\n",
    "                    ehr_by_var_df = pd.concat([ehr_by_var_df,df])\n",
    "\n",
    "                ehr_by_var_df = ehr_by_var_df.set_index(['Diversity Categories',' '])\n",
    "\n",
    "        return ehr_by_var_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T15:16:29.215706Z",
     "start_time": "2022-10-20T15:16:29.194702Z"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile -a ehr_report.py\n",
    "\n",
    "class by_site:\n",
    "    \n",
    "    def __init__(self, historic_ehr_df, denominator, dataset = dataset):\n",
    "        self.historic_ehr_df = historic_ehr_df\n",
    "        self.dataset = dataset\n",
    "        self.denominator = denominator\n",
    " \n",
    "    def heatmap(self, which):\n",
    "        \n",
    "        def ehr_domain(historic_ehr_df = self.historic_ehr_df):\n",
    "            by_site1 = historic_ehr_df.copy()[['person_id','ehr_domain','ehr_site']].drop_duplicates()\n",
    "            row_totals = by_site1[['person_id', 'ehr_domain']].drop_duplicates()\n",
    "            row_totals = row_totals.groupby(['ehr_domain'], as_index = False).nunique()\n",
    "            row_totals['ehr_site'] = 'TOTAL PIDS'\n",
    "\n",
    "            by_site = pd.concat([by_site1.groupby(['ehr_site','ehr_domain'], as_index = False).nunique()\n",
    "                                 , row_totals])\n",
    "            by_site = by_site.pivot(index = ['ehr_site'] ,columns = ['ehr_domain']).fillna(0).astype('int')\n",
    "            by_site.columns = [c[1] for c in by_site.columns]\n",
    "            by_site.index.names = ['EHR Site']\n",
    "            \n",
    "            return by_site\n",
    "\n",
    "        def vocabulary(historic_ehr_df = self.historic_ehr_df):\n",
    "            ehr_vocab = historic_ehr_df[['person_id','ehr_site','vocabulary']].drop_duplicates() \n",
    "\n",
    "            remove_vocabs = ['Visit', 'CMS Place of Service', 'UB04 Pt dis status','Medicare Specialty', 'None', 'OMOP Extension']\n",
    "            other_vocab = ['Cancer Modifier','None', 'CIEL', 'DRG'\n",
    "                           'OMOP Extension', 'NDC', 'CVX', 'Multum', 'HemOnc', 'PPI', 'Nebraska Lexicon']#+remove_vocabs\n",
    "            icd10 = ['ICD10CM','ICD10PCS']\n",
    "            rxnorm = ['RxNorm','RxNorm Extension']\n",
    "\n",
    "            col_totals = ehr_vocab[['person_id','ehr_site']].drop_duplicates()\n",
    "            col_totals = col_totals.groupby('ehr_site').nunique()\n",
    "            col_totals.columns = ['Any EHR']\n",
    "\n",
    "            vocab_by_site = ehr_vocab.copy()[~ehr_vocab.vocabulary.isin(remove_vocabs)].drop_duplicates()\n",
    "            vocab_by_site.loc[vocab_by_site.vocabulary.isin(other_vocab),'vocabulary'] = 'Others'\n",
    "            vocab_by_site.loc[vocab_by_site.vocabulary.isin(icd10),'vocabulary'] = 'ICD10'\n",
    "            vocab_by_site.loc[vocab_by_site.vocabulary.isin(rxnorm),'vocabulary'] = 'RxNorm'\n",
    "\n",
    "            row_totals = vocab_by_site.copy()[['person_id', 'vocabulary']].drop_duplicates()\n",
    "            row_totals = row_totals.groupby(['vocabulary'], as_index = False).nunique()\n",
    "            row_totals = row_totals.T\n",
    "            row_totals.columns = list(row_totals.loc['vocabulary'])\n",
    "            row_totals = row_totals.drop('vocabulary')   \n",
    "            row_totals.index = ['TOTAL PIDS']\n",
    "            row_totals['Any EHR'] = historic_ehr_df.person_id.nunique()\n",
    "\n",
    "            vocab_by_site = vocab_by_site.groupby(['ehr_site','vocabulary'], as_index = False).nunique()\n",
    "            vocab_by_site = vocab_by_site.pivot(index = ['ehr_site'] ,columns = ['vocabulary']).fillna(0).astype('int')\n",
    "            vocab_by_site.columns = [c[1] for c in vocab_by_site.columns]\n",
    "            vocab_by_site.index.names = ['EHR Site']\n",
    "\n",
    "            vocab_by_site = pd.concat([vocab_by_site, col_totals],1).sort_values('Any EHR', ascending = False)\n",
    "            vocab_by_site = pd.concat([row_totals, vocab_by_site])\n",
    "            vocab_by_site = vocab_by_site[sorted(vocab_by_site.columns)]\n",
    "            \n",
    "            return vocab_by_site\n",
    "  \n",
    "        def heatmap_code(raw_heatmap_df, which = which, total_col= 'Any EHR', w = 23,l = 30\n",
    "                         , denominator = self.denominator):\n",
    "\n",
    "            #format heatmap data   \n",
    "            columns_dict = dict()\n",
    "            heatmap_df = raw_heatmap_df.fillna(0).astype('int64')\n",
    "            for n_col in heatmap_df.columns:\n",
    "\n",
    "                heatmap_df[n_col+' %'] = heatmap_df[n_col]/denominator\n",
    "                columns_dict[n_col] = n_col+' %'\n",
    "\n",
    "            heatmap_df.index.name =  'EHR Sites'\n",
    "            heatmap_df = combine_count_and_perc(heatmap_df, columns_dict, drop = False)\n",
    "\n",
    "            heatmap0_df = heatmap_df.sort_values(total_col, ascending = False)\n",
    "            heatmap_clean_df = heatmap0_df[[c for c in heatmap0_df.columns if '%' not in c and '_str' not in c and 'and' not in c]]\n",
    "            heatmap_annot = heatmap0_df[[c for c in heatmap0_df.columns if 'and %' in c ]]\n",
    "            \n",
    "            plot_title = f'\\nCount (and %) of Participants with EHR Data by EHR Site & {which.title()}\\n'\n",
    "            #######\n",
    "            sns.set(rc={'figure.figsize':(w, l)})\n",
    "            sns.set(font_scale = 1.5)\n",
    "            g = sns.heatmap(heatmap_clean_df.sort_values(total_col, ascending = False)\n",
    "                            , annot=heatmap_annot.values\n",
    "                            , annot_kws={'size': 16}\n",
    "                            , fmt=\"\"\n",
    "                            , cmap=\"Blues\", linewidths=.5 , linecolor='black', robust = True\n",
    "                           )\n",
    "\n",
    "            plt.title(plot_title, fontsize=20)\n",
    "            plt.tick_params(right=False, top=True, labelright=False, labeltop=True)\n",
    "            plt.show()\n",
    "\n",
    "            current_cdr = dataset.split('.')[1] \n",
    "            print(f'''\\n*The denominator for all percentages is the Total Number of Participants in the current CDR ({current_cdr}), N = {'{:,}'.format(denominator)}''')\n",
    "    \n",
    "        if which.lower() == 'domain':\n",
    "            raw_heatmap_df = ehr_domain()\n",
    "            heatmap_code(raw_heatmap_df = raw_heatmap_df)\n",
    "\n",
    "        else:\n",
    "            if which.lower() == 'vocabulary':\n",
    "                raw_heatmap_df = vocabulary()\n",
    "                heatmap_code(raw_heatmap_df = raw_heatmap_df, w = 28, l = 32)\n",
    "                print(\"'Others' Category includes: 'Cancer Modifier','None', 'CIEL', 'DRG','OMOP Extension', 'NDC', 'CVX', 'Multum', 'HemOnc', 'PPI', 'Nebraska Lexicon'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a ehr_report.py\n",
    "\n",
    "############################################## ADDITIONAL DATA FORMATTING #####################################################\n",
    "def format_numbers(df):\n",
    "    # format the counts and percentage columns\n",
    "    formated_df = df.copy()\n",
    "    for col in formated_df.columns:\n",
    "        if formated_df[col].dtype == 'int64':\n",
    "            less_than_20 = formated_df.loc[formated_df[col] <20, col].values\n",
    "            formated_df.loc[formated_df[col].astype('int64') <20, col]= '<20'\n",
    "            \n",
    "            formated_df.loc[formated_df[col] != '<20', col] = \\\n",
    "                    ['{:,}'.format(i) for i in formated_df.loc[formated_df[col]!= '<20', col]]           \n",
    "            \n",
    "        else:\n",
    "            if (formated_df[col].dtype == 'float64') & np.all(formated_df[col].values<=1):\n",
    "                formated_df[col] = ['{:.0%}'.format(i) for i in formated_df[col]]\n",
    "            \n",
    "    return formated_df\n",
    "\n",
    "def combine_count_and_perc(df, count_perc_cols_dic, drop = False):    \n",
    "    df_comb = df.copy()\n",
    "    for count_col in count_perc_cols_dic:\n",
    "        perc_col = count_perc_cols_dic[count_col]\n",
    "        df_comb[count_col+'_str'] = df_comb[count_col]\n",
    "        df_comb[perc_col+'_str'] = df_comb[perc_col]\n",
    "        df_comb[[count_col+'_str', perc_col+'_str']] = format_numbers(df_comb[[count_col+'_str', perc_col+'_str']])\n",
    "        df_comb.loc[df_comb[count_col+'_str'].str.contains('<20'), perc_col+'_str']= '-'\n",
    "        df_comb.loc[(~df_comb[count_col+'_str'].str.contains('<20')) & (df_comb[perc_col] <0.01)\n",
    "                    , perc_col+'_str']= '<1%'\n",
    "        \n",
    "        new_col_name = count_col+' (and %)'\n",
    "        df_comb[new_col_name] = df_comb[count_col+'_str']+' ('+df_comb[perc_col+'_str']+')'\n",
    "        \n",
    "        if drop == True:\n",
    "            df_comb = df_comb.drop([count_col, count_col+'_str', perc_col, perc_col+'_str'],1)\n",
    "    return df_comb\n",
    "\n",
    "\n",
    "####\n",
    "\n",
    "generic_demog_cat = ['Multiple Selections', 'None Of These', 'Skip', 'Not Specified','TOTAL']\n",
    "sex_index_order = ['Female', 'Male', 'Intersex']+generic_demog_cat\n",
    "\n",
    "race_index_order = ['White', 'Black', 'Hispanic','Asian', 'MENA (Middle Eastern and North African)'\n",
    "                     , 'NHPI (Native Hawaiian and Other Pacific Islander)', 'More Than One Population'\n",
    "                     ]+generic_demog_cat\n",
    "\n",
    "ethnicity_index_order = ['Not Hispanic Or Latino', 'Hispanic Or Latino']+generic_demog_cat\n",
    "\n",
    "age_index_order = ['18-29','30-39', '40-49', '50-59','60-69', '70-79', '80-89', '90+', 'TOTAL']\n",
    "\n",
    "gender_index_order = ['Woman', 'Man', 'Non Binary', 'Transgender']+generic_demog_cat\n",
    "\n",
    "income_index_order = ['Less 10K', '10K 25K', '25K 35K', '35K 50K', '50K 75K'\n",
    "                      , '75K 100K','100K 150K', '150K 200K', 'More 200K']+generic_demog_cat\n",
    "\n",
    "education_index_order = ['Never Attended', 'One Through Four'\n",
    "                         , 'Five Through Eight','Nine Through Eleven'\n",
    "                         , 'Twelve Or Ged', 'College One To Three' \n",
    "                         , 'College Graduate', 'Advanced Degree'\n",
    "                         ]+generic_demog_cat\n",
    "\n",
    "employment_index_order = ['Employed For Wages', 'Self Employed'\n",
    "                          , 'Out Of Work One Or More','Out Of Work Less Than One'\n",
    "                          ,'Student', 'Homemaker','Retired', 'Unable To Work'\n",
    "                          ]+generic_demog_cat\n",
    "\n",
    "sorting_dict = {#'pm':pm_index_order\n",
    "                'sex_assigned_at_birth': sex_index_order\n",
    "                ,'race':race_index_order\n",
    "                ,'ethnicity': ethnicity_index_order\n",
    "                , 'age_group':age_index_order\n",
    "                , 'gender_identity':gender_index_order\n",
    "                ,'annual_income':income_index_order\n",
    "                ,'educational_attainment':education_index_order\n",
    "                ,'employment':employment_index_order\n",
    "               }\n",
    "\n",
    "##################\n",
    "def format_index_or_col(df, d_type, what = 'index', n=0, sorting_dict = sorting_dict):\n",
    "    \n",
    "    column_name = what if what in df.columns else df.columns[0]\n",
    "\n",
    "    items_to_sort_dict = {'index':df.index, column_name:df[column_name], 'columns':df.columns}\n",
    "    items_to_sort = items_to_sort_dict[what].unique()\n",
    "\n",
    "    sorter = []\n",
    "    for p in sorting_dict[d_type]:\n",
    "        sorter = sorter+[i for i in items_to_sort if p.lower() in i.lower() and i not in sorter]\n",
    "    \n",
    "    donot_title = ['MENA (Middle Eastern and North African)'\n",
    "                   ,'NHPI (Native Hawaiian and Other Pacific Islander)', 'TOTAL']    \n",
    "    if what.lower() == 'index':\n",
    "        df_ordered = df.copy().reindex(sorter)\n",
    "        df_ordered.index = [i.title() for i in df_ordered.index if 'str' in str(type(i)) and i not in donot_title]+\\\n",
    "                            [i for i in df_ordered.index if 'str' in str(type(i)) and i in donot_title]\n",
    "                \n",
    "    else:\n",
    "        if what.lower() == column_name:\n",
    "            #print('COLNAME')\n",
    "            df_ordered = df.copy()\n",
    "            df_ordered[column_name] = pd.Categorical(df_ordered[column_name], categories=sorter, ordered=True)\n",
    "            df_ordered = df_ordered.sort_values(column_name)\n",
    "        \n",
    "        else:\n",
    "            if what.lower() == 'columns':\n",
    "                df_ordered = df.copy()[sorter]\n",
    "                df_ordered.columns = [i.title() for i in df_ordered.columns]\n",
    "            \n",
    "    return df_ordered\n",
    "\n",
    "\n",
    "def style_df(df, note = None):\n",
    "    \n",
    "    styled_df = df.copy()\n",
    "    styled_df.index.names = [i.replace('_',' ').title() for i in styled_df.index.names]\n",
    "    \n",
    "    if np.all([len(i) ==1 for i in styled_df.columns.values]):\n",
    "        styled_df.columns = [i.replace('_',' ').title() for i in styled_df.columns]\n",
    "        \n",
    "    styled_df = styled_df.astype('str')\n",
    "    \n",
    "    # Style the datframe for display\n",
    "    s = styled_df.astype('str').style\n",
    "    s.set_table_styles([\n",
    "            {'selector': 'th','props': 'font-size: 1.1em'}, \n",
    "            {'selector': 'th.col_heading', 'props': 'text-align: center'},\n",
    "            {'selector': 'th.col_heading.level0', 'props': 'font-size: 1.2em;'},\n",
    "            {'selector': 'td', 'props': 'text-align: right; font-weight: normal; font-size: 1.2em'},\n",
    "            \n",
    "            ], overwrite=False)\n",
    "    \n",
    "    for cols in df.columns:\n",
    "        s.set_table_styles({\n",
    "                cols: [{'selector': 'th', 'props': 'border-left: 0.1px solid #808080'},\n",
    "                       {'selector': 'td', 'props': 'border-left: 0.1px solid #808080'}]\n",
    "            }, overwrite=False, axis=0)\n",
    "\n",
    "    display(s)\n",
    "    notes = {'note1':'''\\n* blabla.'''\n",
    "             ,'note2': '''* .'''}\n",
    "\n",
    "    if note:\n",
    "        print(notes[note])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload file to bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload py file from cloud to bucket\n",
    "\n",
    "py_file = 'ehr_report.py'\n",
    "upload_blob(source_file_name = py_file\n",
    "            , destination_blob_name = f'notebooks/code/{py_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
